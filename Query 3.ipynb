{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e03132-f27f-4f58-9a33-91221cae12c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>384</td><td>application_1738075734771_0385</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-12.eu-central-1.compute.internal:20888/proxy/application_1738075734771_0385/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-194.eu-central-1.compute.internal:8042/node/containerlogs/container_1738075734771_0385_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BROADCAST Join Strategy:\n",
      "\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|               Area|Avg Income Per Person ($)|Crime Ratio Per Person|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|  Pacific Palisades|        70656.11282274863|   0.45085501138400425|\n",
      "|Palisades Highlands|        66867.43986433603|    0.2055830941821028|\n",
      "|   Marina Peninsula|        65235.69402813004|    0.6124048881715471|\n",
      "|            Bel Air|        63041.33809466166|    0.4275511439293064|\n",
      "|      Beverly Crest|        60947.49019768682|    0.3713395127553113|\n",
      "|          Brentwood|       60840.624859219824|    0.5036005597078598|\n",
      "|  Mandeville Canyon|        55572.10949582431|   0.26229508196721313|\n",
      "|        Playa Vista|        50264.47187990141|    0.8157069235939951|\n",
      "|            Carthay|       49841.164527155335|    0.9322445879225219|\n",
      "|             Venice|       47614.883340996166|    1.2549272030651342|\n",
      "|       Century City|       46103.510597140456|    0.8558452481076535|\n",
      "|      Playa Del Rey|          45522.596580114|    0.7770740975300824|\n",
      "|        Studio City|        44049.85263005362|    0.9295754238516157|\n",
      "|    Hollywood Hills|       43015.988205771646|    0.8126545975981359|\n",
      "|      South Carthay|       39831.340037649854|     0.723174477360547|\n",
      "|   West Los Angeles|        39714.00529781941|    0.8311722523049905|\n",
      "|       Miracle Mile|        38834.84611073052|    0.8820452139253908|\n",
      "|        Rancho Park|       38740.063860206516|    1.2552819698173154|\n",
      "|             Encino|        38338.00564358072|     0.703747432052705|\n",
      "|       Sherman Oaks|       37767.445673661336|    0.7903687241383545|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time for BROADCAST join: 25.037757635116577 seconds\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (43)\n",
      "+- Sort (42)\n",
      "   +- Exchange (41)\n",
      "      +- Project (40)\n",
      "         +- BroadcastHashJoin Inner BuildRight (39)\n",
      "            :- HashAggregate (22)\n",
      "            :  +- Exchange (21)\n",
      "            :     +- HashAggregate (20)\n",
      "            :        +- Project (19)\n",
      "            :           +- BroadcastIndexJoin (18)\n",
      "            :              :- Union (7)\n",
      "            :              :  :- Project (3)\n",
      "            :              :  :  +- Filter (2)\n",
      "            :              :  :     +- Scan csv  (1)\n",
      "            :              :  +- Project (6)\n",
      "            :              :     +- Filter (5)\n",
      "            :              :        +- Scan csv  (4)\n",
      "            :              +- SpatialIndex (17)\n",
      "            :                 +- Filter (16)\n",
      "            :                    +- ObjectHashAggregate (15)\n",
      "            :                       +- Exchange (14)\n",
      "            :                          +- ObjectHashAggregate (13)\n",
      "            :                             +- Project (12)\n",
      "            :                                +- Filter (11)\n",
      "            :                                   +- Generate (10)\n",
      "            :                                      +- Filter (9)\n",
      "            :                                         +- Scan geojson  (8)\n",
      "            +- BroadcastExchange (38)\n",
      "               +- Project (37)\n",
      "                  +- HashAggregate (36)\n",
      "                     +- Exchange (35)\n",
      "                        +- HashAggregate (34)\n",
      "                           +- Project (33)\n",
      "                              +- BroadcastHashJoin Inner BuildRight (32)\n",
      "                                 :- Project (27)\n",
      "                                 :  +- Filter (26)\n",
      "                                 :     +- Generate (25)\n",
      "                                 :        +- Filter (24)\n",
      "                                 :           +- Scan geojson  (23)\n",
      "                                 +- BroadcastExchange (31)\n",
      "                                    +- Project (30)\n",
      "                                       +- Filter (29)\n",
      "                                          +- Scan csv  (28)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [LAT#68, LON#69]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "Condition : ((isnotnull(LAT#68) AND isnotnull(LON#69)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#404]\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [2]: [LAT#142, LON#143]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(5) Filter\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "Condition : ((isnotnull(LAT#142) AND isnotnull(LON#143)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(6) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#598]\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "\n",
      "(7) Union\n",
      "\n",
      "(8) Scan geojson \n",
      "Output [1]: [features#225]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(9) Filter\n",
      "Input [1]: [features#225]\n",
      "Condition : ((size(features#225, true) > 0) AND isnotnull(features#225))\n",
      "\n",
      "(10) Generate\n",
      "Input [1]: [features#225]\n",
      "Arguments: explode(features#225), false, [features#233]\n",
      "\n",
      "(11) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND isnotnull(features#233.properties.COMM))\n",
      "\n",
      "(12) Project\n",
      "Output [2]: [features#233.properties.COMM AS COMM#249, features#233.geometry AS geometry#236]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(13) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, geometry#236]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [buf#555]\n",
      "Results [2]: [COMM#249, buf#556]\n",
      "\n",
      "(14) Exchange\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=945]\n",
      "\n",
      "(15) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [ST_Union_Aggr(geometry#236)#383]\n",
      "Results [2]: [COMM#249, ST_Union_Aggr(geometry#236)#383 AS geometry#384]\n",
      "\n",
      "(16) Filter\n",
      "Input [2]: [COMM#249, geometry#384]\n",
      "Condition : isnotnull(geometry#384)\n",
      "\n",
      "(17) SpatialIndex\n",
      "Arguments: geometry#384: geometry, RTREE, false, false\n",
      "\n",
      "(18) BroadcastIndexJoin\n",
      "Arguments: geometry#404: geometry, RightSide, LeftSide, Inner, WITHIN\n",
      "\n",
      "(19) Project\n",
      "Output [1]: [COMM#249]\n",
      "Input [3]: [geometry#404, COMM#249, geometry#384]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [1]: [COMM#249]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#553L]\n",
      "Results [2]: [COMM#249, count#554L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=953]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#444L]\n",
      "Results [2]: [COMM#249, count(1)#444L AS Total Crimes#445L]\n",
      "\n",
      "(23) Scan geojson \n",
      "Output [1]: [features#500]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(24) Filter\n",
      "Input [1]: [features#500]\n",
      "Condition : ((size(features#500, true) > 0) AND isnotnull(features#500))\n",
      "\n",
      "(25) Generate\n",
      "Input [1]: [features#500]\n",
      "Arguments: explode(features#500), false, [features#233]\n",
      "\n",
      "(26) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND (isnotnull(features#233.properties.ZCTA10) AND isnotnull(features#233.properties.COMM)))\n",
      "\n",
      "(27) Project\n",
      "Output [4]: [features#233.properties.COMM AS COMM#510, features#233.properties.HOUSING10 AS HOUSING10#516L, features#233.properties.POP_2010 AS POP_2010#519L, features#233.properties.ZCTA10 AS ZCTA10#527]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(28) Scan csv \n",
      "Output [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(29) Filter\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Condition : isnotnull(Zip Code#218)\n",
      "\n",
      "(30) Project\n",
      "Output [2]: [Zip Code#218, cast(regexp_replace(Estimated Median Income#220, [^0-9.], , 1) as double) AS Estimated Median Income#399]\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "\n",
      "(31) BroadcastExchange\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#399]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=955]\n",
      "\n",
      "(32) BroadcastHashJoin\n",
      "Left keys [1]: [cast(ZCTA10#527 as int)]\n",
      "Right keys [1]: [Zip Code#218]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(33) Project\n",
      "Output [3]: [COMM#510, POP_2010#519L, (cast(HOUSING10#516L as double) * Estimated Median Income#399) AS Total Income Per Block#465]\n",
      "Input [6]: [COMM#510, HOUSING10#516L, POP_2010#519L, ZCTA10#527, Zip Code#218, Estimated Median Income#399]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [3]: [COMM#510, POP_2010#519L, Total Income Per Block#465]\n",
      "Keys [1]: [COMM#510]\n",
      "Functions [2]: [partial_sum(Total Income Per Block#465), partial_sum(POP_2010#519L)]\n",
      "Aggregate Attributes [2]: [sum#557, sum#559L]\n",
      "Results [3]: [COMM#510, sum#558, sum#560L]\n",
      "\n",
      "(35) Exchange\n",
      "Input [3]: [COMM#510, sum#558, sum#560L]\n",
      "Arguments: hashpartitioning(COMM#510, 1000), ENSURE_REQUIREMENTS, [plan_id=960]\n",
      "\n",
      "(36) HashAggregate\n",
      "Input [3]: [COMM#510, sum#558, sum#560L]\n",
      "Keys [1]: [COMM#510]\n",
      "Functions [2]: [sum(Total Income Per Block#465), sum(POP_2010#519L)]\n",
      "Aggregate Attributes [2]: [sum(Total Income Per Block#465)#484, sum(POP_2010#519L)#486L]\n",
      "Results [3]: [COMM#510, sum(Total Income Per Block#465)#484 AS Total Income#485, sum(POP_2010#519L)#486L AS Total Population#487L]\n",
      "\n",
      "(37) Project\n",
      "Output [3]: [COMM#510, (Total Income#485 / cast(Total Population#487L as double)) AS Avg Income Per Person ($)#491, Total Population#487L]\n",
      "Input [3]: [COMM#510, Total Income#485, Total Population#487L]\n",
      "\n",
      "(38) BroadcastExchange\n",
      "Input [3]: [COMM#510, Avg Income Per Person ($)#491, Total Population#487L]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=964]\n",
      "\n",
      "(39) BroadcastHashJoin\n",
      "Left keys [1]: [COMM#249]\n",
      "Right keys [1]: [COMM#510]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(40) Project\n",
      "Output [3]: [COMM#249 AS Area#539, Avg Income Per Person ($)#491, (cast(Total Crimes#445L as double) / cast(Total Population#487L as double)) AS Crime Ratio Per Person#533]\n",
      "Input [5]: [COMM#249, Total Crimes#445L, COMM#510, Avg Income Per Person ($)#491, Total Population#487L]\n",
      "\n",
      "(41) Exchange\n",
      "Input [3]: [Area#539, Avg Income Per Person ($)#491, Crime Ratio Per Person#533]\n",
      "Arguments: rangepartitioning(Avg Income Per Person ($)#491 DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=968]\n",
      "\n",
      "(42) Sort\n",
      "Input [3]: [Area#539, Avg Income Per Person ($)#491, Crime Ratio Per Person#533]\n",
      "Arguments: [Avg Income Per Person ($)#491 DESC NULLS LAST], true, 0\n",
      "\n",
      "(43) AdaptiveSparkPlan\n",
      "Output [3]: [Area#539, Avg Income Per Person ($)#491, Crime Ratio Per Person#533]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "MERGE Join Strategy:\n",
      "\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|               Area|Avg Income Per Person ($)|Crime Ratio Per Person|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|  Pacific Palisades|        70656.11282274863|   0.45085501138400425|\n",
      "|Palisades Highlands|        66867.43986433603|    0.2055830941821028|\n",
      "|   Marina Peninsula|        65235.69402813004|    0.6124048881715471|\n",
      "|            Bel Air|        63041.33809466166|    0.4275511439293064|\n",
      "|      Beverly Crest|        60947.49019768682|    0.3713395127553113|\n",
      "|          Brentwood|       60840.624859219824|    0.5036005597078598|\n",
      "|  Mandeville Canyon|        55572.10949582431|   0.26229508196721313|\n",
      "|        Playa Vista|        50264.47187990141|    0.8157069235939951|\n",
      "|            Carthay|       49841.164527155335|    0.9322445879225219|\n",
      "|             Venice|       47614.883340996166|    1.2549272030651342|\n",
      "|       Century City|       46103.510597140456|    0.8558452481076535|\n",
      "|      Playa Del Rey|          45522.596580114|    0.7770740975300824|\n",
      "|        Studio City|        44049.85263005362|    0.9295754238516157|\n",
      "|    Hollywood Hills|       43015.988205771646|    0.8126545975981359|\n",
      "|      South Carthay|       39831.340037649854|     0.723174477360547|\n",
      "|   West Los Angeles|        39714.00529781941|    0.8311722523049905|\n",
      "|       Miracle Mile|        38834.84611073052|    0.8820452139253908|\n",
      "|        Rancho Park|       38740.063860206516|    1.2552819698173154|\n",
      "|             Encino|        38338.00564358072|     0.703747432052705|\n",
      "|       Sherman Oaks|       37767.445673661336|    0.7903687241383545|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time for MERGE join: 22.66466784477234 seconds\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (44)\n",
      "+- Sort (43)\n",
      "   +- Exchange (42)\n",
      "      +- Project (41)\n",
      "         +- SortMergeJoin Inner (40)\n",
      "            :- Sort (23)\n",
      "            :  +- HashAggregate (22)\n",
      "            :     +- Exchange (21)\n",
      "            :        +- HashAggregate (20)\n",
      "            :           +- Project (19)\n",
      "            :              +- BroadcastIndexJoin (18)\n",
      "            :                 :- Union (7)\n",
      "            :                 :  :- Project (3)\n",
      "            :                 :  :  +- Filter (2)\n",
      "            :                 :  :     +- Scan csv  (1)\n",
      "            :                 :  +- Project (6)\n",
      "            :                 :     +- Filter (5)\n",
      "            :                 :        +- Scan csv  (4)\n",
      "            :                 +- SpatialIndex (17)\n",
      "            :                    +- Filter (16)\n",
      "            :                       +- ObjectHashAggregate (15)\n",
      "            :                          +- Exchange (14)\n",
      "            :                             +- ObjectHashAggregate (13)\n",
      "            :                                +- Project (12)\n",
      "            :                                   +- Filter (11)\n",
      "            :                                      +- Generate (10)\n",
      "            :                                         +- Filter (9)\n",
      "            :                                            +- Scan geojson  (8)\n",
      "            +- Sort (39)\n",
      "               +- Project (38)\n",
      "                  +- HashAggregate (37)\n",
      "                     +- Exchange (36)\n",
      "                        +- HashAggregate (35)\n",
      "                           +- Project (34)\n",
      "                              +- BroadcastHashJoin Inner BuildRight (33)\n",
      "                                 :- Project (28)\n",
      "                                 :  +- Filter (27)\n",
      "                                 :     +- Generate (26)\n",
      "                                 :        +- Filter (25)\n",
      "                                 :           +- Scan geojson  (24)\n",
      "                                 +- BroadcastExchange (32)\n",
      "                                    +- Project (31)\n",
      "                                       +- Filter (30)\n",
      "                                          +- Scan csv  (29)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [LAT#68, LON#69]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "Condition : ((isnotnull(LAT#68) AND isnotnull(LON#69)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#404]\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [2]: [LAT#142, LON#143]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(5) Filter\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "Condition : ((isnotnull(LAT#142) AND isnotnull(LON#143)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(6) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#702]\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "\n",
      "(7) Union\n",
      "\n",
      "(8) Scan geojson \n",
      "Output [1]: [features#225]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(9) Filter\n",
      "Input [1]: [features#225]\n",
      "Condition : ((size(features#225, true) > 0) AND isnotnull(features#225))\n",
      "\n",
      "(10) Generate\n",
      "Input [1]: [features#225]\n",
      "Arguments: explode(features#225), false, [features#233]\n",
      "\n",
      "(11) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND isnotnull(features#233.properties.COMM))\n",
      "\n",
      "(12) Project\n",
      "Output [2]: [features#233.properties.COMM AS COMM#249, features#233.geometry AS geometry#236]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(13) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, geometry#236]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [buf#555]\n",
      "Results [2]: [COMM#249, buf#556]\n",
      "\n",
      "(14) Exchange\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=2139]\n",
      "\n",
      "(15) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [ST_Union_Aggr(geometry#236)#383]\n",
      "Results [2]: [COMM#249, ST_Union_Aggr(geometry#236)#383 AS geometry#384]\n",
      "\n",
      "(16) Filter\n",
      "Input [2]: [COMM#249, geometry#384]\n",
      "Condition : isnotnull(geometry#384)\n",
      "\n",
      "(17) SpatialIndex\n",
      "Arguments: geometry#384: geometry, RTREE, false, false\n",
      "\n",
      "(18) BroadcastIndexJoin\n",
      "Arguments: geometry#404: geometry, RightSide, LeftSide, Inner, WITHIN\n",
      "\n",
      "(19) Project\n",
      "Output [1]: [COMM#249]\n",
      "Input [3]: [geometry#404, COMM#249, geometry#384]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [1]: [COMM#249]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#553L]\n",
      "Results [2]: [COMM#249, count#554L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=2146]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#444L]\n",
      "Results [2]: [COMM#249, count(1)#444L AS Total Crimes#445L]\n",
      "\n",
      "(23) Sort\n",
      "Input [2]: [COMM#249, Total Crimes#445L]\n",
      "Arguments: [COMM#249 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(24) Scan geojson \n",
      "Output [1]: [features#609]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(25) Filter\n",
      "Input [1]: [features#609]\n",
      "Condition : ((size(features#609, true) > 0) AND isnotnull(features#609))\n",
      "\n",
      "(26) Generate\n",
      "Input [1]: [features#609]\n",
      "Arguments: explode(features#609), false, [features#233]\n",
      "\n",
      "(27) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND (isnotnull(features#233.properties.ZCTA10) AND isnotnull(features#233.properties.COMM)))\n",
      "\n",
      "(28) Project\n",
      "Output [4]: [features#233.properties.COMM AS COMM#619, features#233.properties.HOUSING10 AS HOUSING10#625L, features#233.properties.POP_2010 AS POP_2010#628L, features#233.properties.ZCTA10 AS ZCTA10#636]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(29) Scan csv \n",
      "Output [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(30) Filter\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Condition : isnotnull(Zip Code#218)\n",
      "\n",
      "(31) Project\n",
      "Output [2]: [Zip Code#218, cast(regexp_replace(Estimated Median Income#220, [^0-9.], , 1) as double) AS Estimated Median Income#399]\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "\n",
      "(32) BroadcastExchange\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#399]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2102]\n",
      "\n",
      "(33) BroadcastHashJoin\n",
      "Left keys [1]: [cast(ZCTA10#636 as int)]\n",
      "Right keys [1]: [Zip Code#218]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(34) Project\n",
      "Output [3]: [COMM#619, POP_2010#628L, (cast(HOUSING10#625L as double) * Estimated Median Income#399) AS Total Income Per Block#465]\n",
      "Input [6]: [COMM#619, HOUSING10#625L, POP_2010#628L, ZCTA10#636, Zip Code#218, Estimated Median Income#399]\n",
      "\n",
      "(35) HashAggregate\n",
      "Input [3]: [COMM#619, POP_2010#628L, Total Income Per Block#465]\n",
      "Keys [1]: [COMM#619]\n",
      "Functions [2]: [partial_sum(Total Income Per Block#465), partial_sum(POP_2010#628L)]\n",
      "Aggregate Attributes [2]: [sum#557, sum#663L]\n",
      "Results [3]: [COMM#619, sum#558, sum#664L]\n",
      "\n",
      "(36) Exchange\n",
      "Input [3]: [COMM#619, sum#558, sum#664L]\n",
      "Arguments: hashpartitioning(COMM#619, 1000), ENSURE_REQUIREMENTS, [plan_id=2107]\n",
      "\n",
      "(37) HashAggregate\n",
      "Input [3]: [COMM#619, sum#558, sum#664L]\n",
      "Keys [1]: [COMM#619]\n",
      "Functions [2]: [sum(Total Income Per Block#465), sum(POP_2010#628L)]\n",
      "Aggregate Attributes [2]: [sum(Total Income Per Block#465)#484, sum(POP_2010#628L)#486L]\n",
      "Results [3]: [COMM#619, sum(Total Income Per Block#465)#484 AS Total Income#485, sum(POP_2010#628L)#486L AS Total Population#487L]\n",
      "\n",
      "(38) Project\n",
      "Output [3]: [COMM#619, (Total Income#485 / cast(Total Population#487L as double)) AS Avg Income Per Person ($)#491, Total Population#487L]\n",
      "Input [3]: [COMM#619, Total Income#485, Total Population#487L]\n",
      "\n",
      "(39) Sort\n",
      "Input [3]: [COMM#619, Avg Income Per Person ($)#491, Total Population#487L]\n",
      "Arguments: [COMM#619 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(40) SortMergeJoin\n",
      "Left keys [1]: [COMM#249]\n",
      "Right keys [1]: [COMM#619]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(41) Project\n",
      "Output [3]: [COMM#249 AS Area#648, Avg Income Per Person ($)#491, (cast(Total Crimes#445L as double) / cast(Total Population#487L as double)) AS Crime Ratio Per Person#642]\n",
      "Input [5]: [COMM#249, Total Crimes#445L, COMM#619, Avg Income Per Person ($)#491, Total Population#487L]\n",
      "\n",
      "(42) Exchange\n",
      "Input [3]: [Area#648, Avg Income Per Person ($)#491, Crime Ratio Per Person#642]\n",
      "Arguments: rangepartitioning(Avg Income Per Person ($)#491 DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=2151]\n",
      "\n",
      "(43) Sort\n",
      "Input [3]: [Area#648, Avg Income Per Person ($)#491, Crime Ratio Per Person#642]\n",
      "Arguments: [Avg Income Per Person ($)#491 DESC NULLS LAST], true, 0\n",
      "\n",
      "(44) AdaptiveSparkPlan\n",
      "Output [3]: [Area#648, Avg Income Per Person ($)#491, Crime Ratio Per Person#642]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "SHUFFLE_HASH Join Strategy:\n",
      "\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|               Area|Avg Income Per Person ($)|Crime Ratio Per Person|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|  Pacific Palisades|        70656.11282274863|   0.45085501138400425|\n",
      "|Palisades Highlands|        66867.43986433603|    0.2055830941821028|\n",
      "|   Marina Peninsula|        65235.69402813004|    0.6124048881715471|\n",
      "|            Bel Air|        63041.33809466166|    0.4275511439293064|\n",
      "|      Beverly Crest|        60947.49019768682|    0.3713395127553113|\n",
      "|          Brentwood|       60840.624859219824|    0.5036005597078598|\n",
      "|  Mandeville Canyon|        55572.10949582431|   0.26229508196721313|\n",
      "|        Playa Vista|        50264.47187990141|    0.8157069235939951|\n",
      "|            Carthay|       49841.164527155335|    0.9322445879225219|\n",
      "|             Venice|       47614.883340996166|    1.2549272030651342|\n",
      "|       Century City|       46103.510597140456|    0.8558452481076535|\n",
      "|      Playa Del Rey|          45522.596580114|    0.7770740975300824|\n",
      "|        Studio City|        44049.85263005362|    0.9295754238516157|\n",
      "|    Hollywood Hills|       43015.988205771646|    0.8126545975981359|\n",
      "|      South Carthay|       39831.340037649854|     0.723174477360547|\n",
      "|   West Los Angeles|        39714.00529781941|    0.8311722523049905|\n",
      "|       Miracle Mile|        38834.84611073052|    0.8820452139253908|\n",
      "|        Rancho Park|       38740.063860206516|    1.2552819698173154|\n",
      "|             Encino|        38338.00564358072|     0.703747432052705|\n",
      "|       Sherman Oaks|       37767.445673661336|    0.7903687241383545|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time for SHUFFLE_HASH join: 19.830262899398804 seconds\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (42)\n",
      "+- Sort (41)\n",
      "   +- Exchange (40)\n",
      "      +- Project (39)\n",
      "         +- ShuffledHashJoin Inner BuildRight (38)\n",
      "            :- HashAggregate (22)\n",
      "            :  +- Exchange (21)\n",
      "            :     +- HashAggregate (20)\n",
      "            :        +- Project (19)\n",
      "            :           +- BroadcastIndexJoin (18)\n",
      "            :              :- Union (7)\n",
      "            :              :  :- Project (3)\n",
      "            :              :  :  +- Filter (2)\n",
      "            :              :  :     +- Scan csv  (1)\n",
      "            :              :  +- Project (6)\n",
      "            :              :     +- Filter (5)\n",
      "            :              :        +- Scan csv  (4)\n",
      "            :              +- SpatialIndex (17)\n",
      "            :                 +- Filter (16)\n",
      "            :                    +- ObjectHashAggregate (15)\n",
      "            :                       +- Exchange (14)\n",
      "            :                          +- ObjectHashAggregate (13)\n",
      "            :                             +- Project (12)\n",
      "            :                                +- Filter (11)\n",
      "            :                                   +- Generate (10)\n",
      "            :                                      +- Filter (9)\n",
      "            :                                         +- Scan geojson  (8)\n",
      "            +- Project (37)\n",
      "               +- HashAggregate (36)\n",
      "                  +- Exchange (35)\n",
      "                     +- HashAggregate (34)\n",
      "                        +- Project (33)\n",
      "                           +- BroadcastHashJoin Inner BuildRight (32)\n",
      "                              :- Project (27)\n",
      "                              :  +- Filter (26)\n",
      "                              :     +- Generate (25)\n",
      "                              :        +- Filter (24)\n",
      "                              :           +- Scan geojson  (23)\n",
      "                              +- BroadcastExchange (31)\n",
      "                                 +- Project (30)\n",
      "                                    +- Filter (29)\n",
      "                                       +- Scan csv  (28)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [LAT#68, LON#69]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "Condition : ((isnotnull(LAT#68) AND isnotnull(LON#69)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#404]\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [2]: [LAT#142, LON#143]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(5) Filter\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "Condition : ((isnotnull(LAT#142) AND isnotnull(LON#143)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(6) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#807]\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "\n",
      "(7) Union\n",
      "\n",
      "(8) Scan geojson \n",
      "Output [1]: [features#225]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(9) Filter\n",
      "Input [1]: [features#225]\n",
      "Condition : ((size(features#225, true) > 0) AND isnotnull(features#225))\n",
      "\n",
      "(10) Generate\n",
      "Input [1]: [features#225]\n",
      "Arguments: explode(features#225), false, [features#233]\n",
      "\n",
      "(11) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND isnotnull(features#233.properties.COMM))\n",
      "\n",
      "(12) Project\n",
      "Output [2]: [features#233.properties.COMM AS COMM#249, features#233.geometry AS geometry#236]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(13) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, geometry#236]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [buf#555]\n",
      "Results [2]: [COMM#249, buf#556]\n",
      "\n",
      "(14) Exchange\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=3280]\n",
      "\n",
      "(15) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [ST_Union_Aggr(geometry#236)#383]\n",
      "Results [2]: [COMM#249, ST_Union_Aggr(geometry#236)#383 AS geometry#384]\n",
      "\n",
      "(16) Filter\n",
      "Input [2]: [COMM#249, geometry#384]\n",
      "Condition : isnotnull(geometry#384)\n",
      "\n",
      "(17) SpatialIndex\n",
      "Arguments: geometry#384: geometry, RTREE, false, false\n",
      "\n",
      "(18) BroadcastIndexJoin\n",
      "Arguments: geometry#404: geometry, RightSide, LeftSide, Inner, WITHIN\n",
      "\n",
      "(19) Project\n",
      "Output [1]: [COMM#249]\n",
      "Input [3]: [geometry#404, COMM#249, geometry#384]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [1]: [COMM#249]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#553L]\n",
      "Results [2]: [COMM#249, count#554L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=3287]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#444L]\n",
      "Results [2]: [COMM#249, count(1)#444L AS Total Crimes#445L]\n",
      "\n",
      "(23) Scan geojson \n",
      "Output [1]: [features#714]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(24) Filter\n",
      "Input [1]: [features#714]\n",
      "Condition : ((size(features#714, true) > 0) AND isnotnull(features#714))\n",
      "\n",
      "(25) Generate\n",
      "Input [1]: [features#714]\n",
      "Arguments: explode(features#714), false, [features#233]\n",
      "\n",
      "(26) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND (isnotnull(features#233.properties.ZCTA10) AND isnotnull(features#233.properties.COMM)))\n",
      "\n",
      "(27) Project\n",
      "Output [4]: [features#233.properties.COMM AS COMM#724, features#233.properties.HOUSING10 AS HOUSING10#730L, features#233.properties.POP_2010 AS POP_2010#733L, features#233.properties.ZCTA10 AS ZCTA10#741]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(28) Scan csv \n",
      "Output [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(29) Filter\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Condition : isnotnull(Zip Code#218)\n",
      "\n",
      "(30) Project\n",
      "Output [2]: [Zip Code#218, cast(regexp_replace(Estimated Median Income#220, [^0-9.], , 1) as double) AS Estimated Median Income#399]\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "\n",
      "(31) BroadcastExchange\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#399]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3247]\n",
      "\n",
      "(32) BroadcastHashJoin\n",
      "Left keys [1]: [cast(ZCTA10#741 as int)]\n",
      "Right keys [1]: [Zip Code#218]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(33) Project\n",
      "Output [3]: [COMM#724, POP_2010#733L, (cast(HOUSING10#730L as double) * Estimated Median Income#399) AS Total Income Per Block#465]\n",
      "Input [6]: [COMM#724, HOUSING10#730L, POP_2010#733L, ZCTA10#741, Zip Code#218, Estimated Median Income#399]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [3]: [COMM#724, POP_2010#733L, Total Income Per Block#465]\n",
      "Keys [1]: [COMM#724]\n",
      "Functions [2]: [partial_sum(Total Income Per Block#465), partial_sum(POP_2010#733L)]\n",
      "Aggregate Attributes [2]: [sum#557, sum#768L]\n",
      "Results [3]: [COMM#724, sum#558, sum#769L]\n",
      "\n",
      "(35) Exchange\n",
      "Input [3]: [COMM#724, sum#558, sum#769L]\n",
      "Arguments: hashpartitioning(COMM#724, 1000), ENSURE_REQUIREMENTS, [plan_id=3252]\n",
      "\n",
      "(36) HashAggregate\n",
      "Input [3]: [COMM#724, sum#558, sum#769L]\n",
      "Keys [1]: [COMM#724]\n",
      "Functions [2]: [sum(Total Income Per Block#465), sum(POP_2010#733L)]\n",
      "Aggregate Attributes [2]: [sum(Total Income Per Block#465)#484, sum(POP_2010#733L)#486L]\n",
      "Results [3]: [COMM#724, sum(Total Income Per Block#465)#484 AS Total Income#485, sum(POP_2010#733L)#486L AS Total Population#487L]\n",
      "\n",
      "(37) Project\n",
      "Output [3]: [COMM#724, (Total Income#485 / cast(Total Population#487L as double)) AS Avg Income Per Person ($)#491, Total Population#487L]\n",
      "Input [3]: [COMM#724, Total Income#485, Total Population#487L]\n",
      "\n",
      "(38) ShuffledHashJoin\n",
      "Left keys [1]: [COMM#249]\n",
      "Right keys [1]: [COMM#724]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(39) Project\n",
      "Output [3]: [COMM#249 AS Area#753, Avg Income Per Person ($)#491, (cast(Total Crimes#445L as double) / cast(Total Population#487L as double)) AS Crime Ratio Per Person#747]\n",
      "Input [5]: [COMM#249, Total Crimes#445L, COMM#724, Avg Income Per Person ($)#491, Total Population#487L]\n",
      "\n",
      "(40) Exchange\n",
      "Input [3]: [Area#753, Avg Income Per Person ($)#491, Crime Ratio Per Person#747]\n",
      "Arguments: rangepartitioning(Avg Income Per Person ($)#491 DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=3291]\n",
      "\n",
      "(41) Sort\n",
      "Input [3]: [Area#753, Avg Income Per Person ($)#491, Crime Ratio Per Person#747]\n",
      "Arguments: [Avg Income Per Person ($)#491 DESC NULLS LAST], true, 0\n",
      "\n",
      "(42) AdaptiveSparkPlan\n",
      "Output [3]: [Area#753, Avg Income Per Person ($)#491, Crime Ratio Per Person#747]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "SHUFFLE_REPLICATE_NL Join Strategy:\n",
      "\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|               Area|Avg Income Per Person ($)|Crime Ratio Per Person|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "|  Pacific Palisades|        70656.11282274863|   0.45085501138400425|\n",
      "|Palisades Highlands|        66867.43986433603|    0.2055830941821028|\n",
      "|   Marina Peninsula|        65235.69402813004|    0.6124048881715471|\n",
      "|            Bel Air|        63041.33809466166|    0.4275511439293064|\n",
      "|      Beverly Crest|        60947.49019768682|    0.3713395127553113|\n",
      "|          Brentwood|       60840.624859219824|    0.5036005597078598|\n",
      "|  Mandeville Canyon|        55572.10949582431|   0.26229508196721313|\n",
      "|        Playa Vista|        50264.47187990141|    0.8157069235939951|\n",
      "|            Carthay|       49841.164527155335|    0.9322445879225219|\n",
      "|             Venice|       47614.883340996166|    1.2549272030651342|\n",
      "|       Century City|       46103.510597140456|    0.8558452481076535|\n",
      "|      Playa Del Rey|          45522.596580114|    0.7770740975300824|\n",
      "|        Studio City|        44049.85263005362|    0.9295754238516157|\n",
      "|    Hollywood Hills|       43015.988205771646|    0.8126545975981359|\n",
      "|      South Carthay|       39831.340037649854|     0.723174477360547|\n",
      "|   West Los Angeles|        39714.00529781941|    0.8311722523049905|\n",
      "|       Miracle Mile|        38834.84611073052|    0.8820452139253908|\n",
      "|        Rancho Park|       38740.063860206516|    1.2552819698173154|\n",
      "|             Encino|        38338.00564358072|     0.703747432052705|\n",
      "|       Sherman Oaks|       37767.445673661336|    0.7903687241383545|\n",
      "+-------------------+-------------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time for SHUFFLE_REPLICATE_NL join: 17.658957958221436 seconds\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (42)\n",
      "+- Sort (41)\n",
      "   +- Exchange (40)\n",
      "      +- Project (39)\n",
      "         +- CartesianProduct Inner (38)\n",
      "            :- HashAggregate (22)\n",
      "            :  +- Exchange (21)\n",
      "            :     +- HashAggregate (20)\n",
      "            :        +- Project (19)\n",
      "            :           +- BroadcastIndexJoin (18)\n",
      "            :              :- Union (7)\n",
      "            :              :  :- Project (3)\n",
      "            :              :  :  +- Filter (2)\n",
      "            :              :  :     +- Scan csv  (1)\n",
      "            :              :  +- Project (6)\n",
      "            :              :     +- Filter (5)\n",
      "            :              :        +- Scan csv  (4)\n",
      "            :              +- SpatialIndex (17)\n",
      "            :                 +- Filter (16)\n",
      "            :                    +- ObjectHashAggregate (15)\n",
      "            :                       +- Exchange (14)\n",
      "            :                          +- ObjectHashAggregate (13)\n",
      "            :                             +- Project (12)\n",
      "            :                                +- Filter (11)\n",
      "            :                                   +- Generate (10)\n",
      "            :                                      +- Filter (9)\n",
      "            :                                         +- Scan geojson  (8)\n",
      "            +- Project (37)\n",
      "               +- HashAggregate (36)\n",
      "                  +- Exchange (35)\n",
      "                     +- HashAggregate (34)\n",
      "                        +- Project (33)\n",
      "                           +- BroadcastHashJoin Inner BuildRight (32)\n",
      "                              :- Project (27)\n",
      "                              :  +- Filter (26)\n",
      "                              :     +- Generate (25)\n",
      "                              :        +- Filter (24)\n",
      "                              :           +- Scan geojson  (23)\n",
      "                              +- BroadcastExchange (31)\n",
      "                                 +- Project (30)\n",
      "                                    +- Filter (29)\n",
      "                                       +- Scan csv  (28)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [LAT#68, LON#69]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "Condition : ((isnotnull(LAT#68) AND isnotnull(LON#69)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#404]\n",
      "Input [2]: [LAT#68, LON#69]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [2]: [LAT#142, LON#143]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<LAT:double,LON:double>\n",
      "\n",
      "(5) Filter\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "Condition : ((isnotnull(LAT#142) AND isnotnull(LON#143)) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(6) Project\n",
      "Output [1]: [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS geometry#912]\n",
      "Input [2]: [LAT#142, LON#143]\n",
      "\n",
      "(7) Union\n",
      "\n",
      "(8) Scan geojson \n",
      "Output [1]: [features#225]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(9) Filter\n",
      "Input [1]: [features#225]\n",
      "Condition : ((size(features#225, true) > 0) AND isnotnull(features#225))\n",
      "\n",
      "(10) Generate\n",
      "Input [1]: [features#225]\n",
      "Arguments: explode(features#225), false, [features#233]\n",
      "\n",
      "(11) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND isnotnull(features#233.properties.COMM))\n",
      "\n",
      "(12) Project\n",
      "Output [2]: [features#233.properties.COMM AS COMM#249, features#233.geometry AS geometry#236]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(13) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, geometry#236]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [buf#555]\n",
      "Results [2]: [COMM#249, buf#556]\n",
      "\n",
      "(14) Exchange\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=4348]\n",
      "\n",
      "(15) ObjectHashAggregate\n",
      "Input [2]: [COMM#249, buf#556]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [st_union_aggr(geometry#236, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@5508859d, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)]\n",
      "Aggregate Attributes [1]: [ST_Union_Aggr(geometry#236)#383]\n",
      "Results [2]: [COMM#249, ST_Union_Aggr(geometry#236)#383 AS geometry#384]\n",
      "\n",
      "(16) Filter\n",
      "Input [2]: [COMM#249, geometry#384]\n",
      "Condition : isnotnull(geometry#384)\n",
      "\n",
      "(17) SpatialIndex\n",
      "Arguments: geometry#384: geometry, RTREE, false, false\n",
      "\n",
      "(18) BroadcastIndexJoin\n",
      "Arguments: geometry#404: geometry, RightSide, LeftSide, Inner, WITHIN\n",
      "\n",
      "(19) Project\n",
      "Output [1]: [COMM#249]\n",
      "Input [3]: [geometry#404, COMM#249, geometry#384]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [1]: [COMM#249]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#553L]\n",
      "Results [2]: [COMM#249, count#554L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Arguments: hashpartitioning(COMM#249, 1000), ENSURE_REQUIREMENTS, [plan_id=4355]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [2]: [COMM#249, count#554L]\n",
      "Keys [1]: [COMM#249]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#444L]\n",
      "Results [2]: [COMM#249, count(1)#444L AS Total Crimes#445L]\n",
      "\n",
      "(23) Scan geojson \n",
      "Output [1]: [features#819]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG10:string,BG10FIP10:string,BG12:string,CB10:string,CEN_FIP13:string,CITY:string,CITYCOM:string,COMM:string,CT10:string,CT12:string,CTCB10:string,HD_2012:bigint,HD_NAME:string,HOUSING10:bigint,LA_FIP10:string,OBJECTID:bigint,POP_2010:bigint,PUMA10:string,SPA_2012:bigint,SPA_NAME:string,SUP_DIST:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,ZCTA10:string>,type:string>>>\n",
      "\n",
      "(24) Filter\n",
      "Input [1]: [features#819]\n",
      "Condition : ((size(features#819, true) > 0) AND isnotnull(features#819))\n",
      "\n",
      "(25) Generate\n",
      "Input [1]: [features#819]\n",
      "Arguments: explode(features#819), false, [features#233]\n",
      "\n",
      "(26) Filter\n",
      "Input [1]: [features#233]\n",
      "Condition : ((isnotnull(features#233.properties.CITY) AND (features#233.properties.CITY = Los Angeles)) AND (isnotnull(features#233.properties.ZCTA10) AND isnotnull(features#233.properties.COMM)))\n",
      "\n",
      "(27) Project\n",
      "Output [4]: [features#233.properties.COMM AS COMM#829, features#233.properties.HOUSING10 AS HOUSING10#835L, features#233.properties.POP_2010 AS POP_2010#838L, features#233.properties.ZCTA10 AS ZCTA10#846]\n",
      "Input [1]: [features#233]\n",
      "\n",
      "(28) Scan csv \n",
      "Output [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv]\n",
      "PushedFilters: [IsNotNull(Zip Code)]\n",
      "ReadSchema: struct<Zip Code:int,Estimated Median Income:string>\n",
      "\n",
      "(29) Filter\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "Condition : isnotnull(Zip Code#218)\n",
      "\n",
      "(30) Project\n",
      "Output [2]: [Zip Code#218, cast(regexp_replace(Estimated Median Income#220, [^0-9.], , 1) as double) AS Estimated Median Income#399]\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#220]\n",
      "\n",
      "(31) BroadcastExchange\n",
      "Input [2]: [Zip Code#218, Estimated Median Income#399]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=4316]\n",
      "\n",
      "(32) BroadcastHashJoin\n",
      "Left keys [1]: [cast(ZCTA10#846 as int)]\n",
      "Right keys [1]: [Zip Code#218]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(33) Project\n",
      "Output [3]: [COMM#829, POP_2010#838L, (cast(HOUSING10#835L as double) * Estimated Median Income#399) AS Total Income Per Block#465]\n",
      "Input [6]: [COMM#829, HOUSING10#835L, POP_2010#838L, ZCTA10#846, Zip Code#218, Estimated Median Income#399]\n",
      "\n",
      "(34) HashAggregate\n",
      "Input [3]: [COMM#829, POP_2010#838L, Total Income Per Block#465]\n",
      "Keys [1]: [COMM#829]\n",
      "Functions [2]: [partial_sum(Total Income Per Block#465), partial_sum(POP_2010#838L)]\n",
      "Aggregate Attributes [2]: [sum#557, sum#873L]\n",
      "Results [3]: [COMM#829, sum#558, sum#874L]\n",
      "\n",
      "(35) Exchange\n",
      "Input [3]: [COMM#829, sum#558, sum#874L]\n",
      "Arguments: hashpartitioning(COMM#829, 1000), ENSURE_REQUIREMENTS, [plan_id=4321]\n",
      "\n",
      "(36) HashAggregate\n",
      "Input [3]: [COMM#829, sum#558, sum#874L]\n",
      "Keys [1]: [COMM#829]\n",
      "Functions [2]: [sum(Total Income Per Block#465), sum(POP_2010#838L)]\n",
      "Aggregate Attributes [2]: [sum(Total Income Per Block#465)#484, sum(POP_2010#838L)#486L]\n",
      "Results [3]: [COMM#829, sum(Total Income Per Block#465)#484 AS Total Income#485, sum(POP_2010#838L)#486L AS Total Population#487L]\n",
      "\n",
      "(37) Project\n",
      "Output [3]: [COMM#829, (Total Income#485 / cast(Total Population#487L as double)) AS Avg Income Per Person ($)#491, Total Population#487L]\n",
      "Input [3]: [COMM#829, Total Income#485, Total Population#487L]\n",
      "\n",
      "(38) CartesianProduct\n",
      "Join type: Inner\n",
      "Join condition: (COMM#249 = COMM#829)\n",
      "\n",
      "(39) Project\n",
      "Output [3]: [COMM#249 AS Area#858, Avg Income Per Person ($)#491, (cast(Total Crimes#445L as double) / cast(Total Population#487L as double)) AS Crime Ratio Per Person#852]\n",
      "Input [5]: [COMM#249, Total Crimes#445L, COMM#829, Avg Income Per Person ($)#491, Total Population#487L]\n",
      "\n",
      "(40) Exchange\n",
      "Input [3]: [Area#858, Avg Income Per Person ($)#491, Crime Ratio Per Person#852]\n",
      "Arguments: rangepartitioning(Avg Income Per Person ($)#491 DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=4359]\n",
      "\n",
      "(41) Sort\n",
      "Input [3]: [Area#858, Avg Income Per Person ($)#491, Crime Ratio Per Person#852]\n",
      "Arguments: [Avg Income Per Person ($)#491 DESC NULLS LAST], true, 0\n",
      "\n",
      "(42) AdaptiveSparkPlan\n",
      "Output [3]: [Area#858, Avg Income Per Person ($)#491, Crime Ratio Per Person#852]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, sum, first, regexp_replace, concat, lit, lower\n",
    "from sedona.spark import *\n",
    "import time\n",
    "\n",
    "# Δημιουργία Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query 3\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sedona Context για GeoJSON δεδομένα\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "crime_2010_2019_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "crime_2020_present_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "income_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\"\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "\n",
    "crime_df_2010_2019 = spark.read.csv(crime_2010_2019_path, header=True, inferSchema=True)\n",
    "crime_df_2020_present = spark.read.csv(crime_2020_present_path, header=True, inferSchema=True)\n",
    "crime_df = crime_df_2010_2019.union(crime_df_2020_present)\n",
    "income_df = spark.read.csv(income_path, header=True, inferSchema=True)\n",
    "\n",
    "# Φόρτωση και επεξεργασία GeoJSON δεδομένων\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "\n",
    "flattened_df = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "\n",
    "# Φιλτράρισμα των τετραγώνων του Los Angeles και επιλογή μόνο των επιθυμητών στηλών\n",
    "LA_blocks = flattened_df.filter(col(\"CITY\") == \"Los Angeles\") \\\n",
    "    .select(\"COMM\", \"HOUSING10\", \"POP_2010\", \"ZCTA10\", \"geometry\")\n",
    "\n",
    "# Φιλτράρισμα των περιοχών του Los Angeles\n",
    "LA_areas = LA_blocks.groupBy(\"COMM\").agg(ST_Union_Aggr(\"geometry\").alias(\"geometry\"))\n",
    "\n",
    "# Αφαίρεση του \"$\" και οποιωνδήποτε κενών ή άλλων μη αριθμητικών χαρακτήρων\n",
    "income_df = income_df.withColumn(\n",
    "    \"Estimated Median Income\",\n",
    "    regexp_replace(col(\"Estimated Median Income\"), r\"[^0-9.]\", \"\").cast(\"double\")\n",
    ")\n",
    "\n",
    "# Δημιουργία γεωμετρικών σημείων για τα εγκλήματα\n",
    "crime_points = crime_df.filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull()) \\\n",
    "    .withColumn(\"geometry\", ST_Point(col(\"LON\"), col(\"LAT\"))) \\\n",
    "    .select(\"geometry\")\n",
    "\n",
    "# Υπολογισμός αριθμού εγκλημάτων ανά περιοχή\n",
    "total_crimes = crime_points.join(\n",
    "    LA_areas.hint(\"BROADCAST\"),                                        #κάνουμε BROADCAST των π΄΄ινακα LA_areas επειδή είναι μικρός\n",
    "    ST_Within(crime_points[\"geometry\"], LA_areas[\"geometry\"]),\n",
    "    \"inner\"\n",
    ").groupBy(\"COMM\").agg(\n",
    "    count(\"*\").alias(\"Total Crimes\")\n",
    ")\n",
    "\n",
    "# Υπολογισμός κατα κεφαλήν εισοδήματος ανά περιοχή\n",
    "average_income_per_person = LA_blocks.join(\n",
    "    income_df.hint(\"BROADCAST\"),                                       #κάνουμε BROADCAST των π΄΄ινακα income_df επειδή είναι μικρός\n",
    "    LA_blocks[\"ZCTA10\"] == income_df[\"Zip Code\"],\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"Total Income Per Block\",\n",
    "    (col(\"HOUSING10\") * col(\"Estimated Median Income\")).alias(\"Total Income Per Block\")\n",
    ").groupBy(\"COMM\").agg(\n",
    "    sum(\"Total Income Per Block\").alias(\"Total Income\"),\n",
    "    sum(\"POP_2010\").alias(\"Total Population\")\n",
    ").withColumn(\n",
    "    \"Avg Income Per Person ($)\",\n",
    "    (col(\"Total Income\") / col(\"Total Population\"))\n",
    ").select(\n",
    "    \"COMM\", \n",
    "    \"Avg Income Per Person ($)\",\n",
    "    \"Total Population\"\n",
    ")\n",
    "\n",
    "# Στρατηγική BROADCAST Join\n",
    "\n",
    "# Χρόνος πριν την εκτέλεση\n",
    "broadcast_start_time = time.time()\n",
    "\n",
    "# Υπολογισμός μέσου αριθμού εγκλημάτων ανά άτομο\n",
    "broadcast_result = total_crimes.join(\n",
    "    average_income_per_person.hint(\"BROADCAST\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"Crime Ratio Per Person\",\n",
    "    (col(\"Total Crimes\") / col(\"Total Population\"))\n",
    ").select(\n",
    "    col(\"COMM\").alias(\"Area\"), \n",
    "    \"Avg Income Per Person ($)\", \n",
    "    \"Crime Ratio Per Person\"\n",
    ").orderBy(\"Avg Income Per Person ($)\", ascending=False)\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων για BROADCAST\n",
    "print(\"BROADCAST Join Strategy:\\n\")\n",
    "broadcast_result.show()\n",
    "\n",
    "# Χρόνος μετά την εκτέλεση\n",
    "broadcast_end_time = time.time()\n",
    "\n",
    "# Υπολογισμός του χρόνου εκτέλεσης\n",
    "broadcast_execution_time = broadcast_end_time - broadcast_start_time\n",
    "print(f\"Execution time for BROADCAST join: {broadcast_execution_time} seconds\\n\")\n",
    "\n",
    "# Explain για BROADCAST\n",
    "broadcast_result.explain(mode=\"formatted\")\n",
    "\n",
    "# Στρατηγική MERGE Join\n",
    "\n",
    "# Χρόνος πριν την εκτέλεση\n",
    "merge_start_time = time.time()\n",
    "\n",
    "# Υπολογισμός μέσου αριθμού εγκλημάτων ανά άτομο\n",
    "merge_result = total_crimes.join(\n",
    "    average_income_per_person.hint(\"MERGE\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"Crime Ratio Per Person\",\n",
    "    (col(\"Total Crimes\") / col(\"Total Population\"))\n",
    ").select(\n",
    "    col(\"COMM\").alias(\"Area\"), \n",
    "    \"Avg Income Per Person ($)\", \n",
    "    \"Crime Ratio Per Person\"\n",
    ").orderBy(\"Avg Income Per Person ($)\", ascending=False)\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων για MERGE\n",
    "print(\"MERGE Join Strategy:\\n\")\n",
    "merge_result.show()\n",
    "\n",
    "# Χρόνος μετά την εκτέλεση\n",
    "merge_end_time = time.time()\n",
    "\n",
    "# Υπολογισμός του χρόνου εκτέλεσης\n",
    "merge_execution_time = merge_end_time - merge_start_time\n",
    "print(f\"Execution time for MERGE join: {merge_execution_time} seconds\\n\")\n",
    "\n",
    "# Explain για MERGE\n",
    "merge_result.explain(mode=\"formatted\")\n",
    "\n",
    "# Στρατηγική SHUFFLE_HASH Join\n",
    "\n",
    "# Χρόνος πριν την εκτέλεση\n",
    "shuffle_hash_start_time = time.time()\n",
    "\n",
    "# Υπολογισμός μέσου αριθμού εγκλημάτων ανά άτομο\n",
    "shuffle_hash_result = total_crimes.join(\n",
    "    average_income_per_person.hint(\"SHUFFLE_HASH\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"Crime Ratio Per Person\",\n",
    "    (col(\"Total Crimes\") / col(\"Total Population\"))\n",
    ").select(\n",
    "    col(\"COMM\").alias(\"Area\"), \n",
    "    \"Avg Income Per Person ($)\", \n",
    "    \"Crime Ratio Per Person\"\n",
    ").orderBy(\"Avg Income Per Person ($)\", ascending=False)\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων για SHUFFLE_HASH\n",
    "print(\"SHUFFLE_HASH Join Strategy:\\n\")\n",
    "shuffle_hash_result.show()\n",
    "\n",
    "# Χρόνος μετά την εκτέλεση\n",
    "shuffle_hash_end_time = time.time()\n",
    "\n",
    "# Υπολογισμός του χρόνου εκτέλεσης\n",
    "shuffle_hash_execution_time = shuffle_hash_end_time - shuffle_hash_start_time\n",
    "print(f\"Execution time for SHUFFLE_HASH join: {shuffle_hash_execution_time} seconds\\n\")\n",
    "\n",
    "# Explain για SHUFFLE_HASH\n",
    "shuffle_hash_result.explain(mode=\"formatted\")\n",
    "\n",
    "# Στρατηγική SHUFFLE_REPLICATE_NL Join\n",
    "\n",
    "# Χρόνος πριν την εκτέλεση\n",
    "shuffle_replicate_nl_start_time = time.time()\n",
    "\n",
    "# Υπολογισμός μέσου αριθμού εγκλημάτων ανά άτομο\n",
    "shuffle_replicate_nl_result = total_crimes.join(\n",
    "    average_income_per_person.hint(\"SHUFFLE_REPLICATE_NL\"),\n",
    "    \"COMM\",\n",
    "    \"inner\"\n",
    ").withColumn(\n",
    "    \"Crime Ratio Per Person\",\n",
    "    (col(\"Total Crimes\") / col(\"Total Population\"))\n",
    ").select(\n",
    "    col(\"COMM\").alias(\"Area\"), \n",
    "    \"Avg Income Per Person ($)\", \n",
    "    \"Crime Ratio Per Person\"\n",
    ").orderBy(\"Avg Income Per Person ($)\", ascending=False)\n",
    "\n",
    "# Εμφάνιση αποτελεσμάτων για SHUFFLE_REPLICATE_NL\n",
    "print(\"SHUFFLE_REPLICATE_NL Join Strategy:\\n\")\n",
    "shuffle_replicate_nl_result.show()\n",
    "\n",
    "# Χρόνος μετά την εκτέλεση\n",
    "shuffle_replicate_nl_end_time = time.time()\n",
    "\n",
    "# Υπολογισμός του χρόνου εκτέλεσης\n",
    "shuffle_replicate_nl_execution_time = shuffle_replicate_nl_end_time - shuffle_replicate_nl_start_time\n",
    "print(f\"Execution time for SHUFFLE_REPLICATE_NL join: {shuffle_replicate_nl_execution_time} seconds\\n\")\n",
    "\n",
    "# Explain για SHUFFLE_REPLICATE_NL\n",
    "shuffle_replicate_nl_result.explain(mode=\"formatted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
